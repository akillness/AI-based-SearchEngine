"""
AI ê¸°ë°˜ ê²€ìƒ‰ì—”ì§„ í”„ë ˆì„ì›Œí¬
=========================

ì´ ëª¨ë“ˆì€ Anthropic Claudeì™€ Brave Search APIë¥¼ í™œìš©í•˜ì—¬ 
ì¸í…”ë¦¬ì „íŠ¸í•œ ì›¹ ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„± ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤.
BERTì™€ FAISSë¥¼ í™œìš©í•œ ë²¡í„° ê¸°ë°˜ ê²€ìƒ‰ë„ ì§€ì›í•©ë‹ˆë‹¤.
"""

import os
import json
import requests
from newspaper import Article
from anthropic import Anthropic
import numpy as np
from transformers import BertTokenizer, BertModel
import faiss
import torch
import logging
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class SearchResult:
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    id: int
    title: str
    url: str
    content: str
    description: str = ""

@dataclass
class VectorSearchResult:
    """ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    document: str
    distance: float
    similarity_score: float = 0.0

class VectorSearchModule:
    """BERTì™€ FAISSë¥¼ í™œìš©í•œ ë²¡í„° ê²€ìƒ‰ ëª¨ë“ˆ"""
    
    def __init__(self, model_name='bert-base-uncased'):
        """ë²¡í„° ê²€ìƒ‰ ëª¨ë“ˆ ì´ˆê¸°í™”"""
        try:
            self.tokenizer = BertTokenizer.from_pretrained(model_name)
            self.model = BertModel.from_pretrained(model_name)
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            self.model.to(self.device)
            logger.info(f"ë²¡í„° ê²€ìƒ‰ ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ: {model_name}")
        except Exception as e:
            logger.error(f"ë²¡í„° ê²€ìƒ‰ ëª¨ë“ˆ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.tokenizer = None
            self.model = None

    def text_to_vector(self, text: str) -> Optional[np.ndarray]:
        """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
        if not self.tokenizer or not self.model:
            return None
        
        try:
            inputs = self.tokenizer(text, return_tensors="pt", max_length=512, 
                                  truncation=True, padding=True)
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            with torch.no_grad():
                outputs = self.model(**inputs)
            
            vector = outputs.last_hidden_state.mean(dim=1).cpu().numpy()
            return vector
        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ ë²¡í„°í™” ì‹¤íŒ¨: {e}")
            return None

    def build_index(self, corpus: List[str]) -> Tuple[Optional[faiss.Index], Optional[List[str]]]:
        """í…ìŠ¤íŠ¸ ì½”í¼ìŠ¤ì— ëŒ€í•´ FAISS ì¸ë±ìŠ¤ êµ¬ì¶•"""
        if not corpus:
            return None, None
        
        vectors = []
        for i, doc in enumerate(corpus):
            logger.info(f"ë²¡í„°í™” ì§„í–‰: {i+1}/{len(corpus)}")
            vec = self.text_to_vector(doc)
            if vec is not None:
                vectors.append(vec)
        
        if not vectors:
            return None, None

        vectors_np = np.vstack(vectors)
        dimension = vectors_np.shape[1]
        
        index = faiss.IndexFlatL2(dimension)
        index.add(vectors_np)
        
        logger.info(f"FAISS ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ: {index.ntotal}ê°œ ë²¡í„°")
        return index, corpus

    def search(self, query: str, index: faiss.Index, corpus: List[str], k: int = 3) -> List[VectorSearchResult]:
        """ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰"""
        if not index or not corpus:
            return []
        
        query_vector = self.text_to_vector(query)
        if query_vector is None:
            return []
        
        distances, indices = index.search(query_vector, k)
        
        results = []
        for i in range(len(indices[0])):
            idx = indices[0][i]
            if 0 <= idx < len(corpus):
                distance = float(distances[0][i])
                similarity = 1.0 / (1.0 + distance)
                
                results.append(VectorSearchResult(
                    document=corpus[idx],
                    distance=distance,
                    similarity_score=similarity
                ))
        
        return results

class AISearchEngine:
    """AI ê¸°ë°˜ ê²€ìƒ‰ì—”ì§„ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, anthropic_api_key: str = None, brave_api_key: str = None):
        """ê²€ìƒ‰ì—”ì§„ ì´ˆê¸°í™”"""
        self.anthropic_api_key = anthropic_api_key or os.environ.get("ANTHROPIC_API_KEY")
        self.brave_api_key = brave_api_key or os.environ.get("BRAVE_API_KEY")
        
        # Anthropic í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        if self.anthropic_api_key and self.anthropic_api_key != "your_anthropic_api_key":
            self.anthropic_client = Anthropic(api_key=self.anthropic_api_key)
            logger.info("Anthropic í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        else:
            self.anthropic_client = None
            logger.warning("Anthropic API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ë²¡í„° ê²€ìƒ‰ ëª¨ë“ˆ ì´ˆê¸°í™”
        self.vector_module = VectorSearchModule()

    def generate_related_queries(self, query: str) -> List[str]:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ì¿¼ë¦¬ ìƒì„±"""
        if not self.anthropic_client:
            return []
        
        try:
            message = self.anthropic_client.messages.create(
                model="claude-3-sonnet-20240229",
                max_tokens=1000,
                messages=[
                    {
                        "role": "user", 
                        "content": f"ë‹¤ìŒ ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ 5ê°œì˜ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”: '{query}'\nê´€ë ¨ ì¿¼ë¦¬ëŠ” ì›ë˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì°¾ëŠ” ë° ë„ì›€ì´ ë˜ì–´ì•¼ í•˜ë©°, JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”."
                    }
                ]
            )
            
            response_text = message.content[0].text
            related_queries = json.loads(response_text)
            return related_queries if isinstance(related_queries, list) else []
        except Exception as e:
            logger.error(f"ê´€ë ¨ ì¿¼ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
            return []

    def get_search_results(self, query: str) -> List[Dict]:
        """Brave Search APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°"""
        if not self.brave_api_key:
            logger.warning("Brave API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        
        url = "https://api.search.brave.com/res/v1/web/search"
        params = {"q": query, "count": 3}
        headers = {"X-Subscription-Token": self.brave_api_key}
        
        try:
            response = requests.get(url, params=params, headers=headers)
            response.raise_for_status()
            data = response.json()
            return data.get("web", {}).get("results", [])
        except Exception as e:
            logger.error(f"ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return []

    def get_url_content(self, url: str) -> str:
        """URLì˜ ì½˜í…ì¸  ì¶”ì¶œ"""
        try:
            article = Article(url)
            article.download()
            article.parse()
            return article.text
        except Exception as e:
            logger.error(f"URL ì½˜í…ì¸  ì¶”ì¶œ ì‹¤íŒ¨ {url}: {e}")
            return ""

    def generate_response(self, query: str, search_results: List[SearchResult]) -> str:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±"""
        if not self.anthropic_client or not search_results:
            return "ì¶©ë¶„í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        context_parts = []
        for result in search_results:
            content_snippet = result.content[:500] + "..." if len(result.content) > 500 else result.content
            context_parts.append(f"[{result.id}] {result.title}: {content_snippet}")
        
        context = "\n".join(context_parts)
        
        try:
            message = self.anthropic_client.messages.create(
                model="claude-3-sonnet-20240229",
                max_tokens=1500,
                messages=[
                    {
                        "role": "user",
                        "content": f"""ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”. ë‹µë³€ì—ëŠ” ì¶œì²˜ë¥¼ [ë²ˆí˜¸] í˜•ì‹ìœ¼ë¡œ í¬í•¨í•´ì£¼ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {query}

ë‹µë³€:"""
                    }
                ]
            )
            
            return message.content[0].text
        except Exception as e:
            logger.error(f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            return "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    def search_and_answer(self, query: str) -> str:
        """ì›¹ ê²€ìƒ‰ ë° LLM ë‹µë³€ ìƒì„± íŒŒì´í”„ë¼ì¸"""
        logger.info(f"ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
        
        # ê´€ë ¨ ì¿¼ë¦¬ ìƒì„±
        related_queries = self.generate_related_queries(query)
        all_queries = [query] + related_queries
        
        # ê²€ìƒ‰ ì‹¤í–‰
        all_results = []
        unique_urls = set()
        
        for search_query in all_queries[:3]:  # ìµœëŒ€ 3ê°œ ì¿¼ë¦¬
            logger.info(f"ê²€ìƒ‰ ì¤‘: {search_query}")
            results = self.get_search_results(search_query)
            
            for result in results:
                url = result.get("url")
                if url and url not in unique_urls:
                    unique_urls.add(url)
                    content = self.get_url_content(url)
                    
                    if content:
                        all_results.append(SearchResult(
                            id=len(all_results) + 1,
                            title=result.get("title", ""),
                            url=url,
                            content=content,
                            description=result.get("description", "")
                        ))
                
                if len(all_results) >= 5:  # ìµœëŒ€ 5ê°œ ê²°ê³¼
                    break
            
            if len(all_results) >= 5:
                break
        
        logger.info(f"ìˆ˜ì§‘ëœ ê²°ê³¼: {len(all_results)}ê°œ")
        
        # ë‹µë³€ ìƒì„±
        return self.generate_response(query, all_results)

def main():
    """ë©”ì¸ í•¨ìˆ˜ - ê²€ìƒ‰ì—”ì§„ ë°ëª¨"""
    print("ğŸ” AI ê¸°ë°˜ ê²€ìƒ‰ì—”ì§„ í”„ë ˆì„ì›Œí¬")
    print("=" * 40)
    
    # ê²€ìƒ‰ì—”ì§„ ì´ˆê¸°í™”
    engine = AISearchEngine()
    
    # ì›¹ ê²€ìƒ‰ ë°ëª¨
    print("\n--- ì›¹ ê²€ìƒ‰ + LLM ë‹µë³€ ë°ëª¨ ---")
    if engine.anthropic_client and engine.brave_api_key:
        query = input("ê²€ìƒ‰í•  ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ")
        if query:
            print("\nê²€ìƒ‰ ì¤‘...")
            answer = engine.search_and_answer(query)
            print(f"\në‹µë³€:\n{answer}")
    else:
        print("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì›¹ ê²€ìƒ‰ ë°ëª¨ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
    
    # ë²¡í„° ê²€ìƒ‰ ë°ëª¨
    print("\n--- ë²¡í„° ê²€ìƒ‰ ë°ëª¨ ---")
    if engine.vector_module.model:
        sample_corpus = [
            "ê¸°í›„ ë³€í™”ëŠ” ì§€êµ¬ ì˜¨ë‚œí™”ë¡œ ì¸í•œ ì „ ì§€êµ¬ì  í™˜ê²½ ë³€í™”ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.",
            "ì¸ê³µì§€ëŠ¥ì€ ê¸°ê³„ê°€ ì¸ê°„ì˜ ì§€ëŠ¥ì„ ëª¨ë°©í•˜ì—¬ í•™ìŠµí•˜ê³  ì¶”ë¡ í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.",
            "Pythonì€ ë°ì´í„° ê³¼í•™ê³¼ ì›¹ ê°œë°œì— ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.",
            "ì—í íƒ‘ì€ í”„ë‘ìŠ¤ íŒŒë¦¬ì— ìœ„ì¹˜í•œ ì² ì œ ê²©ì êµ¬ì¡°ì˜ íƒ‘ì…ë‹ˆë‹¤.",
            "ê´‘í•©ì„±ì€ ì‹ë¬¼ì´ ë¹› ì—ë„ˆì§€ë¥¼ í™”í•™ ì—ë„ˆì§€ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤."
        ]
        
        print(f"ìƒ˜í”Œ ì½”í¼ìŠ¤ ({len(sample_corpus)}ê°œ ë¬¸ì„œ)ë¡œ ì¸ë±ìŠ¤ êµ¬ì¶• ì¤‘...")
        index, corpus = engine.vector_module.build_index(sample_corpus)
        
        if index:
            vector_query = input("ë²¡í„° ê²€ìƒ‰í•  ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ")
            if vector_query:
                results = engine.vector_module.search(vector_query, index, corpus, k=2)
                print("\në²¡í„° ê²€ìƒ‰ ê²°ê³¼:")
                for i, result in enumerate(results, 1):
                    print(f"{i}. ë¬¸ì„œ: {result.document}")
                    print(f"   ìœ ì‚¬ë„: {result.similarity_score:.4f}\n")
    
    print("ê²€ìƒ‰ì—”ì§„ ë°ëª¨ ì™„ë£Œ!")

if __name__ == "__main__":
    main() 